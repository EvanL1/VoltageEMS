//! æ€§èƒ½åŸºå‡†æµ‹è¯•
//!
//! æµ‹è¯•åè®®æ’ä»¶ç³»ç»Ÿçš„æ€§èƒ½æŒ‡æ ‡ï¼ŒåŒ…æ‹¬ååé‡ã€å»¶è¿Ÿã€å†…å­˜ä½¿ç”¨ç­‰

use std::time::{Duration, Instant};
use std::sync::Arc;
use tokio::sync::{Mutex, Semaphore};
use futures::future::join_all;
use sysinfo::{System, SystemExt, ProcessExt};
use std::process;

/// æ€§èƒ½æµ‹è¯•é…ç½®
#[derive(Clone)]
struct BenchmarkConfig {
    /// æµ‹è¯•åç§°
    name: String,
    /// å¹¶å‘è¿æ¥æ•°
    concurrent_connections: usize,
    /// æ¯ä¸ªè¿æ¥çš„æ“ä½œæ•°
    operations_per_connection: usize,
    /// æ“ä½œé—´éš”
    operation_interval: Duration,
    /// æ•°æ®åŒ…å¤§å°
    payload_size: usize,
    /// é¢„çƒ­æ—¶é—´
    warmup_duration: Duration,
    /// æµ‹è¯•æŒç»­æ—¶é—´
    test_duration: Duration,
}

/// æ€§èƒ½æŒ‡æ ‡
#[derive(Debug, Clone)]
struct PerformanceMetrics {
    /// æ€»æ“ä½œæ•°
    total_operations: usize,
    /// æˆåŠŸæ“ä½œæ•°
    successful_operations: usize,
    /// å¤±è´¥æ“ä½œæ•°
    failed_operations: usize,
    /// å¹³å‡å»¶è¿Ÿï¼ˆæ¯«ç§’ï¼‰
    avg_latency_ms: f64,
    /// æœ€å°å»¶è¿Ÿï¼ˆæ¯«ç§’ï¼‰
    min_latency_ms: f64,
    /// æœ€å¤§å»¶è¿Ÿï¼ˆæ¯«ç§’ï¼‰
    max_latency_ms: f64,
    /// P50å»¶è¿Ÿï¼ˆæ¯«ç§’ï¼‰
    p50_latency_ms: f64,
    /// P95å»¶è¿Ÿï¼ˆæ¯«ç§’ï¼‰
    p95_latency_ms: f64,
    /// P99å»¶è¿Ÿï¼ˆæ¯«ç§’ï¼‰
    p99_latency_ms: f64,
    /// ååé‡ï¼ˆæ“ä½œ/ç§’ï¼‰
    throughput_ops_per_sec: f64,
    /// å†…å­˜ä½¿ç”¨ï¼ˆMBï¼‰
    memory_usage_mb: f64,
    /// CPUä½¿ç”¨ç‡ï¼ˆ%ï¼‰
    cpu_usage_percent: f64,
}

/// æ€§èƒ½æµ‹è¯•å™¨
struct PerformanceBenchmark {
    config: BenchmarkConfig,
    metrics: Arc<Mutex<Vec<f64>>>, // å»¶è¿Ÿæ•°æ®
    operations: Arc<Mutex<usize>>, // æ“ä½œè®¡æ•°
    errors: Arc<Mutex<usize>>,     // é”™è¯¯è®¡æ•°
}

impl PerformanceBenchmark {
    fn new(config: BenchmarkConfig) -> Self {
        Self {
            config,
            metrics: Arc::new(Mutex::new(Vec::new())),
            operations: Arc::new(Mutex::new(0)),
            errors: Arc::new(Mutex::new(0)),
        }
    }
    
    /// è¿è¡ŒåŸºå‡†æµ‹è¯•
    async fn run(&self) -> PerformanceMetrics {
        println!("\nğŸš€ Running benchmark: {}", self.config.name);
        println!("Concurrent connections: {}", self.config.concurrent_connections);
        println!("Operations per connection: {}", self.config.operations_per_connection);
        println!("Payload size: {} bytes", self.config.payload_size);
        
        // é¢„çƒ­é˜¶æ®µ
        if self.config.warmup_duration > Duration::ZERO {
            println!("Warming up for {:?}...", self.config.warmup_duration);
            self.warmup().await;
        }
        
        // é‡ç½®è®¡æ•°å™¨
        *self.operations.lock().await = 0;
        *self.errors.lock().await = 0;
        self.metrics.lock().await.clear();
        
        // å¼€å§‹æµ‹è¯•
        println!("Starting benchmark...");
        let start_time = Instant::now();
        let initial_memory = self.get_memory_usage();
        let initial_cpu = self.get_cpu_usage().await;
        
        // åˆ›å»ºå¹¶å‘ä»»åŠ¡
        let tasks = self.create_benchmark_tasks();
        
        // ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆæˆ–è¶…æ—¶
        let _ = tokio::time::timeout(
            self.config.test_duration,
            join_all(tasks)
        ).await;
        
        let elapsed = start_time.elapsed();
        let final_memory = self.get_memory_usage();
        let final_cpu = self.get_cpu_usage().await;
        
        // è®¡ç®—æ€§èƒ½æŒ‡æ ‡
        self.calculate_metrics(
            elapsed,
            initial_memory,
            final_memory,
            initial_cpu,
            final_cpu
        ).await
    }
    
    /// é¢„çƒ­é˜¶æ®µ
    async fn warmup(&self) {
        let warmup_tasks = self.create_benchmark_tasks();
        let _ = tokio::time::timeout(
            self.config.warmup_duration,
            join_all(warmup_tasks)
        ).await;
    }
    
    /// åˆ›å»ºåŸºå‡†æµ‹è¯•ä»»åŠ¡
    fn create_benchmark_tasks(&self) -> Vec<tokio::task::JoinHandle<()>> {
        let semaphore = Arc::new(Semaphore::new(self.config.concurrent_connections));
        let mut tasks = Vec::new();
        
        for conn_id in 0..self.config.concurrent_connections {
            let sem = Arc::clone(&semaphore);
            let metrics = Arc::clone(&self.metrics);
            let operations = Arc::clone(&self.operations);
            let errors = Arc::clone(&self.errors);
            let config = self.config.clone();
            
            let task = tokio::spawn(async move {
                let _permit = sem.acquire().await.unwrap();
                
                for op_id in 0..config.operations_per_connection {
                    let start = Instant::now();
                    
                    // æ¨¡æ‹Ÿåè®®æ“ä½œ
                    match Self::simulate_protocol_operation(&config, conn_id, op_id).await {
                        Ok(_) => {
                            let latency = start.elapsed().as_secs_f64() * 1000.0;
                            metrics.lock().await.push(latency);
                            *operations.lock().await += 1;
                        }
                        Err(_) => {
                            *errors.lock().await += 1;
                        }
                    }
                    
                    // æ“ä½œé—´éš”
                    if config.operation_interval > Duration::ZERO {
                        tokio::time::sleep(config.operation_interval).await;
                    }
                }
            });
            
            tasks.push(task);
        }
        
        tasks
    }
    
    /// æ¨¡æ‹Ÿåè®®æ“ä½œ
    async fn simulate_protocol_operation(
        config: &BenchmarkConfig,
        _conn_id: usize,
        _op_id: usize
    ) -> Result<(), Box<dyn std::error::Error>> {
        // æ¨¡æ‹Ÿæ•°æ®å¤„ç†å»¶è¿Ÿ
        let processing_time = Duration::from_micros(
            (config.payload_size as u64 / 100).max(1)
        );
        tokio::time::sleep(processing_time).await;
        
        // æ¨¡æ‹Ÿéšæœºé”™è¯¯ï¼ˆ1%æ¦‚ç‡ï¼‰
        if rand::random::<f64>() < 0.01 {
            return Err("Simulated error".into());
        }
        
        Ok(())
    }
    
    /// è®¡ç®—æ€§èƒ½æŒ‡æ ‡
    async fn calculate_metrics(
        &self,
        elapsed: Duration,
        initial_memory: f64,
        final_memory: f64,
        initial_cpu: f64,
        final_cpu: f64
    ) -> PerformanceMetrics {
        let mut latencies = self.metrics.lock().await;
        let total_ops = *self.operations.lock().await;
        let total_errors = *self.errors.lock().await;
        
        // æ’åºå»¶è¿Ÿæ•°æ®
        latencies.sort_by(|a, b| a.partial_cmp(b).unwrap());
        
        let metrics = if !latencies.is_empty() {
            let sum: f64 = latencies.iter().sum();
            let avg = sum / latencies.len() as f64;
            let min = *latencies.first().unwrap();
            let max = *latencies.last().unwrap();
            
            let p50_idx = (latencies.len() as f64 * 0.50) as usize;
            let p95_idx = (latencies.len() as f64 * 0.95) as usize;
            let p99_idx = (latencies.len() as f64 * 0.99) as usize;
            
            let p50 = latencies.get(p50_idx).copied().unwrap_or(0.0);
            let p95 = latencies.get(p95_idx).copied().unwrap_or(0.0);
            let p99 = latencies.get(p99_idx).copied().unwrap_or(0.0);
            
            PerformanceMetrics {
                total_operations: total_ops + total_errors,
                successful_operations: total_ops,
                failed_operations: total_errors,
                avg_latency_ms: avg,
                min_latency_ms: min,
                max_latency_ms: max,
                p50_latency_ms: p50,
                p95_latency_ms: p95,
                p99_latency_ms: p99,
                throughput_ops_per_sec: total_ops as f64 / elapsed.as_secs_f64(),
                memory_usage_mb: final_memory - initial_memory,
                cpu_usage_percent: (final_cpu - initial_cpu).max(0.0),
            }
        } else {
            PerformanceMetrics {
                total_operations: 0,
                successful_operations: 0,
                failed_operations: total_errors,
                avg_latency_ms: 0.0,
                min_latency_ms: 0.0,
                max_latency_ms: 0.0,
                p50_latency_ms: 0.0,
                p95_latency_ms: 0.0,
                p99_latency_ms: 0.0,
                throughput_ops_per_sec: 0.0,
                memory_usage_mb: 0.0,
                cpu_usage_percent: 0.0,
            }
        };
        
        self.print_metrics(&metrics);
        metrics
    }
    
    /// è·å–å†…å­˜ä½¿ç”¨
    fn get_memory_usage(&self) -> f64 {
        let mut system = System::new_all();
        system.refresh_all();
        
        let pid = process::id();
        if let Some(process) = system.process(pid as i32) {
            process.memory() as f64 / 1024.0 / 1024.0 // è½¬æ¢ä¸ºMB
        } else {
            0.0
        }
    }
    
    /// è·å–CPUä½¿ç”¨ç‡
    async fn get_cpu_usage(&self) -> f64 {
        let mut system = System::new_all();
        system.refresh_all();
        
        // ç­‰å¾…ä¸€æ®µæ—¶é—´ä»¥è·å–å‡†ç¡®çš„CPUä½¿ç”¨ç‡
        tokio::time::sleep(Duration::from_millis(100)).await;
        system.refresh_all();
        
        let pid = process::id();
        if let Some(process) = system.process(pid as i32) {
            process.cpu_usage() as f64
        } else {
            0.0
        }
    }
    
    /// æ‰“å°æ€§èƒ½æŒ‡æ ‡
    fn print_metrics(&self, metrics: &PerformanceMetrics) {
        println!("\nğŸ“Š Performance Metrics");
        println!("{:-<60}", "");
        println!("Total Operations: {}", metrics.total_operations);
        println!("Successful: {} ({:.1}%)", 
            metrics.successful_operations,
            (metrics.successful_operations as f64 / metrics.total_operations as f64) * 100.0
        );
        println!("Failed: {}", metrics.failed_operations);
        println!();
        println!("Throughput: {:.2} ops/sec", metrics.throughput_ops_per_sec);
        println!();
        println!("Latency (ms):");
        println!("  Average: {:.2}", metrics.avg_latency_ms);
        println!("  Min: {:.2}", metrics.min_latency_ms);
        println!("  Max: {:.2}", metrics.max_latency_ms);
        println!("  P50: {:.2}", metrics.p50_latency_ms);
        println!("  P95: {:.2}", metrics.p95_latency_ms);
        println!("  P99: {:.2}", metrics.p99_latency_ms);
        println!();
        println!("Resource Usage:");
        println!("  Memory: {:.2} MB", metrics.memory_usage_mb);
        println!("  CPU: {:.1}%", metrics.cpu_usage_percent);
        println!("{:-<60}", "");
    }
}

/// åŸºå‡†æµ‹è¯•å¥—ä»¶
pub struct BenchmarkSuite;

impl BenchmarkSuite {
    /// è¿è¡Œæ‰€æœ‰åŸºå‡†æµ‹è¯•
    pub async fn run_all() -> Vec<PerformanceMetrics> {
        let mut results = Vec::new();
        
        // åŸºç¡€æ€§èƒ½æµ‹è¯•
        let basic_config = BenchmarkConfig {
            name: "Basic Performance".to_string(),
            concurrent_connections: 10,
            operations_per_connection: 100,
            operation_interval: Duration::from_millis(10),
            payload_size: 1024,
            warmup_duration: Duration::from_secs(2),
            test_duration: Duration::from_secs(10),
        };
        let benchmark = PerformanceBenchmark::new(basic_config);
        results.push(benchmark.run().await);
        
        // é«˜å¹¶å‘æµ‹è¯•
        let high_concurrency_config = BenchmarkConfig {
            name: "High Concurrency".to_string(),
            concurrent_connections: 100,
            operations_per_connection: 50,
            operation_interval: Duration::from_millis(5),
            payload_size: 512,
            warmup_duration: Duration::from_secs(3),
            test_duration: Duration::from_secs(15),
        };
        let benchmark = PerformanceBenchmark::new(high_concurrency_config);
        results.push(benchmark.run().await);
        
        // å¤§æ•°æ®åŒ…æµ‹è¯•
        let large_payload_config = BenchmarkConfig {
            name: "Large Payload".to_string(),
            concurrent_connections: 20,
            operations_per_connection: 50,
            operation_interval: Duration::from_millis(20),
            payload_size: 65536, // 64KB
            warmup_duration: Duration::from_secs(2),
            test_duration: Duration::from_secs(10),
        };
        let benchmark = PerformanceBenchmark::new(large_payload_config);
        results.push(benchmark.run().await);
        
        // æŒç»­è´Ÿè½½æµ‹è¯•
        let sustained_load_config = BenchmarkConfig {
            name: "Sustained Load".to_string(),
            concurrent_connections: 50,
            operations_per_connection: 1000,
            operation_interval: Duration::from_millis(2),
            payload_size: 2048,
            warmup_duration: Duration::from_secs(5),
            test_duration: Duration::from_secs(60),
        };
        let benchmark = PerformanceBenchmark::new(sustained_load_config);
        results.push(benchmark.run().await);
        
        Self::print_summary(&results);
        results
    }
    
    /// æ‰“å°æµ‹è¯•æ€»ç»“
    fn print_summary(results: &[PerformanceMetrics]) {
        println!("\nğŸ Benchmark Summary");
        println!("{:=<80}", "");
        println!("{:<20} {:>15} {:>15} {:>15} {:>15}", 
            "Test", "Throughput", "Avg Latency", "P95 Latency", "Memory");
        println!("{:-<80}", "");
        
        for (i, metrics) in results.iter().enumerate() {
            let test_name = match i {
                0 => "Basic",
                1 => "High Concurrency",
                2 => "Large Payload",
                3 => "Sustained Load",
                _ => "Unknown",
            };
            
            println!("{:<20} {:>15.2} {:>15.2} {:>15.2} {:>15.2}",
                test_name,
                metrics.throughput_ops_per_sec,
                metrics.avg_latency_ms,
                metrics.p95_latency_ms,
                metrics.memory_usage_mb
            );
        }
        println!("{:=<80}", "");
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    
    #[tokio::test]
    async fn test_basic_benchmark() {
        let config = BenchmarkConfig {
            name: "Test Benchmark".to_string(),
            concurrent_connections: 5,
            operations_per_connection: 10,
            operation_interval: Duration::from_millis(1),
            payload_size: 256,
            warmup_duration: Duration::ZERO,
            test_duration: Duration::from_secs(2),
        };
        
        let benchmark = PerformanceBenchmark::new(config);
        let metrics = benchmark.run().await;
        
        assert!(metrics.successful_operations > 0);
        assert!(metrics.throughput_ops_per_sec > 0.0);
        assert!(metrics.avg_latency_ms >= 0.0);
    }
    
    #[tokio::test]
    #[ignore] // å¿½ç•¥é•¿æ—¶é—´è¿è¡Œçš„æµ‹è¯•
    async fn test_full_benchmark_suite() {
        let results = BenchmarkSuite::run_all().await;
        assert_eq!(results.len(), 4);
        
        for metrics in results {
            assert!(metrics.throughput_ops_per_sec > 0.0);
        }
    }
}
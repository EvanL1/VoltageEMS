#!/usr/bin/env python3
"""è´Ÿè½½æµ‹è¯•"""

import os
import requests
import time
import threading
import statistics
import redis


def test_load():
    """æµ‹è¯•ç³»ç»Ÿè´Ÿè½½èƒ½åŠ›"""
    modsrv_url = os.getenv("MODSRV_URL", "http://modsrv:8082")
    redis_url = os.getenv("REDIS_URL", "redis://redis:6379")

    print("ğŸ” å¼€å§‹è´Ÿè½½æµ‹è¯•...")

    # è¿æ¥Redisç›‘æ§æ•°æ®
    redis_client = redis.from_url(redis_url, decode_responses=True)

    # æµ‹è¯•é…ç½®
    load_config = {
        "concurrent_users": 20,
        "requests_per_user": 10,
        "test_duration": 30,  # ç§’
        "ramp_up_time": 5,  # ç§’
    }

    print("è´Ÿè½½æµ‹è¯•é…ç½®:")
    print(f"  - å¹¶å‘ç”¨æˆ·æ•°: {load_config['concurrent_users']}")
    print(f"  - æ¯ç”¨æˆ·è¯·æ±‚æ•°: {load_config['requests_per_user']}")
    print(f"  - æµ‹è¯•æŒç»­æ—¶é—´: {load_config['test_duration']}ç§’")
    print(f"  - å¯åŠ¨æ—¶é—´: {load_config['ramp_up_time']}ç§’")

    # è·³è¿‡å®ä¾‹åˆ›å»ºï¼Œç›´æ¥ä½¿ç”¨é¢„å®šä¹‰æ¨¡å‹
    print("1. ä½¿ç”¨é¢„å®šä¹‰æ¨¡å‹è¿›è¡Œæµ‹è¯•...")
    test_models = ["power_meter_demo", "transformer_demo"]
    print(f"   ä½¿ç”¨æ¨¡å‹: {test_models}")

    # éªŒè¯æ¨¡å‹æ˜¯å¦å¯è®¿é—®
    for model_id in test_models:
        try:
            response = requests.get(f"{modsrv_url}/models/{model_id}", timeout=5)
            if response.status_code == 200:
                print(f"   âœ… æ¨¡å‹ {model_id} å¯è®¿é—®")
            else:
                print(f"   âš ï¸  æ¨¡å‹ {model_id} è®¿é—®å¤±è´¥: {response.status_code}")
        except Exception as e:
            print(f"   âŒ æ¨¡å‹ {model_id} éªŒè¯å¼‚å¸¸: {e}")

    time.sleep(1)  # ç­‰å¾…éªŒè¯å®Œæˆ

    # å®šä¹‰è´Ÿè½½æµ‹è¯•æ“ä½œ
    def api_operations():
        """è¿”å›APIæ“ä½œåˆ—è¡¨"""
        return [
            ("GET", "/health", None, "å¥åº·æ£€æŸ¥"),
            ("GET", "/models", None, "æ¨¡å‹åˆ—è¡¨"),
            ("GET", "/models/power_meter_demo", None, "ç”µè¡¨æ¨¡å‹è¯¦æƒ…"),
            ("GET", "/models/transformer_demo", None, "å˜å‹å™¨æ¨¡å‹è¯¦æƒ…"),
            (
                "POST",
                "/models/power_meter_demo/control/power_limit",
                {"value": 100.0},
                "ç”µè¡¨åŠŸç‡é™åˆ¶æ§åˆ¶",
            ),
            (
                "POST",
                "/models/transformer_demo/control/main_breaker",
                {"value": 1.0},
                "å˜å‹å™¨æ–­è·¯å™¨æ§åˆ¶",
            ),
        ]

    # è´Ÿè½½æµ‹è¯•å·¥ä½œçº¿ç¨‹
    def load_test_worker(worker_id, results_queue, barrier, stop_event):
        """è´Ÿè½½æµ‹è¯•å·¥ä½œçº¿ç¨‹"""
        operations = api_operations()
        local_results = []

        # ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å°±ç»ª
        barrier.wait()

        request_count = 0
        start_time = time.time()

        while not stop_event.is_set():
            for method, endpoint, data, description in operations:
                if stop_event.is_set():
                    break

                try:
                    request_start = time.time()

                    if method == "GET":
                        response = requests.get(f"{modsrv_url}{endpoint}", timeout=10)
                    elif method == "POST":
                        response = requests.post(
                            f"{modsrv_url}{endpoint}",
                            json=data,
                            headers={"Content-Type": "application/json"},
                            timeout=10,
                        )

                    request_end = time.time()
                    response_time = (request_end - request_start) * 1000  # æ¯«ç§’

                    local_results.append(
                        {
                            "worker_id": worker_id,
                            "operation": description,
                            "method": method,
                            "endpoint": endpoint,
                            "status_code": response.status_code,
                            "response_time": response_time,
                            "timestamp": request_start,
                            "success": 200 <= response.status_code < 400,
                        }
                    )

                except Exception as e:
                    request_end = time.time()
                    response_time = (request_end - request_start) * 1000

                    local_results.append(
                        {
                            "worker_id": worker_id,
                            "operation": description,
                            "method": method,
                            "endpoint": endpoint,
                            "status_code": 0,
                            "response_time": response_time,
                            "timestamp": request_start,
                            "success": False,
                            "error": str(e),
                        }
                    )

                request_count += 1

                # æå°çš„å»¶è¿Ÿï¼Œä»…ç”¨äºé¿å…è¿‡åº¦å ç”¨CPU
                time.sleep(0.001)  # 1mså»¶è¿Ÿ

        results_queue.put(local_results)

    # æ‰§è¡Œè´Ÿè½½æµ‹è¯•
    print("2. å¼€å§‹è´Ÿè½½æµ‹è¯•...")

    import queue

    results_queue = queue.Queue()
    barrier = threading.Barrier(
        load_config["concurrent_users"] + 1
    )  # +1 for main thread
    stop_event = threading.Event()

    # å¯åŠ¨å·¥ä½œçº¿ç¨‹
    threads = []
    for i in range(load_config["concurrent_users"]):
        thread = threading.Thread(
            target=load_test_worker, args=(i, results_queue, barrier, stop_event)
        )
        threads.append(thread)
        thread.start()

        # æ¸è¿›å¼å¯åŠ¨
        time.sleep(load_config["ramp_up_time"] / load_config["concurrent_users"])

    # å¼€å§‹æµ‹è¯•
    test_start_time = time.time()
    barrier.wait()  # ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å°±ç»ª
    print(f"   ğŸ“Š è´Ÿè½½æµ‹è¯•å¼€å§‹ï¼Œ{load_config['concurrent_users']} ä¸ªå¹¶å‘ç”¨æˆ·")

    # ç›‘æ§æµ‹è¯•è¿›ç¨‹
    monitor_interval = 5
    next_monitor = test_start_time + monitor_interval

    while time.time() - test_start_time < load_config["test_duration"]:
        current_time = time.time()

        if current_time >= next_monitor:
            elapsed = current_time - test_start_time
            remaining = load_config["test_duration"] - elapsed
            print(
                f"   â±ï¸  æµ‹è¯•è¿›è¡Œä¸­: {elapsed:.1f}s / {load_config['test_duration']}s (å‰©ä½™: {remaining:.1f}s)"
            )
            next_monitor = current_time + monitor_interval

        time.sleep(1)

    # åœæ­¢æµ‹è¯•
    print("   ğŸ›‘ åœæ­¢è´Ÿè½½æµ‹è¯•...")
    stop_event.set()

    # ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆ
    for thread in threads:
        thread.join(timeout=10)

    test_end_time = time.time()
    actual_duration = test_end_time - test_start_time

    # æ”¶é›†ç»“æœ
    print("3. æ”¶é›†æµ‹è¯•ç»“æœ...")
    all_results = []

    while not results_queue.empty():
        worker_results = results_queue.get()
        all_results.extend(worker_results)

    # åˆ†æç»“æœ
    print("4. åˆ†ææµ‹è¯•ç»“æœ...")

    if not all_results:
        print("   âŒ æ²¡æœ‰æ”¶é›†åˆ°æµ‹è¯•ç»“æœ")
        return False

    # åŸºæœ¬ç»Ÿè®¡
    total_requests = len(all_results)
    successful_requests = sum(1 for r in all_results if r["success"])
    failed_requests = total_requests - successful_requests
    success_rate = successful_requests / total_requests * 100

    # å“åº”æ—¶é—´ç»Ÿè®¡
    response_times = [r["response_time"] for r in all_results if r["success"]]

    if response_times:
        avg_response_time = statistics.mean(response_times)
        median_response_time = statistics.median(response_times)
        p95_response_time = sorted(response_times)[int(len(response_times) * 0.95)]
        p99_response_time = sorted(response_times)[int(len(response_times) * 0.99)]
        min_response_time = min(response_times)
        max_response_time = max(response_times)
    else:
        avg_response_time = median_response_time = p95_response_time = (
            p99_response_time
        ) = 0
        min_response_time = max_response_time = 0

    # ååé‡ç»Ÿè®¡
    throughput = total_requests / actual_duration  # è¯·æ±‚/ç§’

    # é”™è¯¯åˆ†æ
    error_types = {}
    for result in all_results:
        if not result["success"]:
            status = result["status_code"]
            error_key = f"HTTP_{status}" if status > 0 else "Connection_Error"
            error_types[error_key] = error_types.get(error_key, 0) + 1

    # è¾“å‡ºç»“æœ
    print("\nğŸ“Š è´Ÿè½½æµ‹è¯•ç»“æœ:")
    print(f"   æ€»è¯·æ±‚æ•°: {total_requests}")
    print(f"   æˆåŠŸè¯·æ±‚: {successful_requests}")
    print(f"   å¤±è´¥è¯·æ±‚: {failed_requests}")
    print(f"   æˆåŠŸç‡: {success_rate:.2f}%")
    print(f"   å®é™…æµ‹è¯•æ—¶é—´: {actual_duration:.2f}ç§’")
    print(f"   å¹³å‡ååé‡: {throughput:.2f} è¯·æ±‚/ç§’")

    print("\nâ±ï¸  å“åº”æ—¶é—´ç»Ÿè®¡ (æ¯«ç§’):")
    print(f"   å¹³å‡å“åº”æ—¶é—´: {avg_response_time:.2f}ms")
    print(f"   ä¸­ä½æ•°å“åº”æ—¶é—´: {median_response_time:.2f}ms")
    print(f"   95%å“åº”æ—¶é—´: {p95_response_time:.2f}ms")
    print(f"   99%å“åº”æ—¶é—´: {p99_response_time:.2f}ms")
    print(f"   æœ€å°å“åº”æ—¶é—´: {min_response_time:.2f}ms")
    print(f"   æœ€å¤§å“åº”æ—¶é—´: {max_response_time:.2f}ms")

    if error_types:
        print("\nâŒ é”™è¯¯ç»Ÿè®¡:")
        for error_type, count in error_types.items():
            print(f"   {error_type}: {count} æ¬¡")

    # è¯„ä¼°æµ‹è¯•ç»“æœ
    performance_issues = []

    if success_rate < 95:
        performance_issues.append(f"æˆåŠŸç‡è¿‡ä½: {success_rate:.2f}%")

    if avg_response_time > 1000:  # 1ç§’
        performance_issues.append(f"å¹³å‡å“åº”æ—¶é—´è¿‡é•¿: {avg_response_time:.2f}ms")

    if p95_response_time > 2000:  # 2ç§’
        performance_issues.append(f"95%å“åº”æ—¶é—´è¿‡é•¿: {p95_response_time:.2f}ms")

    if throughput < 10:  # 10è¯·æ±‚/ç§’
        performance_issues.append(f"ååé‡è¿‡ä½: {throughput:.2f} è¯·æ±‚/ç§’")

    if performance_issues:
        print("\nâš ï¸  æ€§èƒ½é—®é¢˜:")
        for issue in performance_issues:
            print(f"   - {issue}")
    else:
        print("\nâœ… ç³»ç»Ÿæ€§èƒ½è¡¨ç°è‰¯å¥½")

    # Redisæ•°æ®æ£€æŸ¥
    print("5. æ£€æŸ¥Redisæ•°æ®çŠ¶æ€...")
    try:
        info = redis_client.info()
        memory_usage = info.get("used_memory_human", "N/A")
        connected_clients = info.get("connected_clients", "N/A")
        total_commands = info.get("total_commands_processed", "N/A")

        print(f"   Rediså†…å­˜ä½¿ç”¨: {memory_usage}")
        print(f"   è¿æ¥å®¢æˆ·ç«¯æ•°: {connected_clients}")
        print(f"   æ€»å‘½ä»¤æ•°: {total_commands}")

    except Exception as e:
        print(f"   âš ï¸  RedisçŠ¶æ€æ£€æŸ¥å¤±è´¥: {e}")

    # åˆ¤æ–­æµ‹è¯•æ˜¯å¦é€šè¿‡
    test_passed = success_rate >= 90 and avg_response_time <= 2000

    if test_passed:
        print("\nâœ… è´Ÿè½½æµ‹è¯•é€šè¿‡")
    else:
        print("\nâŒ è´Ÿè½½æµ‹è¯•æœªè¾¾åˆ°é¢„æœŸæ ‡å‡†")

    return test_passed


if __name__ == "__main__":
    try:
        if test_load():
            print("è´Ÿè½½æµ‹è¯•: PASS")
        else:
            print("è´Ÿè½½æµ‹è¯•: FAIL - æ€§èƒ½ä¸è¾¾æ ‡")
            exit(1)
    except Exception as e:
        print(f"è´Ÿè½½æµ‹è¯•: FAIL - {e}")
        exit(1)

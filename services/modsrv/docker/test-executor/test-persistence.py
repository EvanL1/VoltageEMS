#!/usr/bin/env python3
"""æ•°æ®æŒç»­æ€§æµ‹è¯•"""

import os
import redis
import time
import requests


def test_data_persistence():
    """æµ‹è¯•æ•°æ®æŒç»­æ€§å’Œä¸€è‡´æ€§"""
    redis_url = os.getenv("REDIS_URL", "redis://redis:6379")
    modsrv_url = os.getenv("MODSRV_URL", "http://modsrv:8082")

    print("ğŸ” å¼€å§‹æ•°æ®æŒç»­æ€§æµ‹è¯•...")

    # è¿æ¥Redis
    redis_client = redis.from_url(redis_url, decode_responses=True)

    # 1. æµ‹è¯•ComsRvæ•°æ®æŒç»­æ€§
    print("1. æµ‹è¯•ComsRvæ•°æ®æŒç»­æ€§...")

    # è®°å½•åˆå§‹æ•°æ®å¿«ç…§
    initial_snapshot = {}
    comsrv_keys = redis_client.keys("comsrv:*")

    for key in comsrv_keys[:10]:  # åªæµ‹è¯•å‰10ä¸ªé”®
        initial_snapshot[key] = redis_client.hgetall(key)

    print(f"   è®°å½•åˆå§‹å¿«ç…§: {len(initial_snapshot)} ä¸ªé”®")

    # ç­‰å¾…ä¸€æ®µæ—¶é—´è®©æ•°æ®æ›´æ–°
    wait_time = 10
    print(f"   ç­‰å¾… {wait_time} ç§’è§‚å¯Ÿæ•°æ®å˜åŒ–...")
    time.sleep(wait_time)

    # æ£€æŸ¥æ•°æ®å˜åŒ–
    changed_keys = 0
    unchanged_keys = 0
    data_consistency_issues = 0

    for key, initial_data in initial_snapshot.items():
        current_data = redis_client.hgetall(key)

        if current_data != initial_data:
            changed_keys += 1

            # æ£€æŸ¥æ•°æ®æ ¼å¼ä¸€è‡´æ€§
            for point_id, value in current_data.items():
                try:
                    float_val = float(value)
                    # æ£€æŸ¥6ä½å°æ•°æ ¼å¼
                    if "." not in value or len(value.split(".")[1]) != 6:
                        data_consistency_issues += 1
                        print(f"   âš ï¸  æ•°æ®æ ¼å¼é—®é¢˜ {key}.{point_id}: {value}")
                except ValueError:
                    data_consistency_issues += 1
                    print(f"   âŒ éæ•°å€¼æ•°æ® {key}.{point_id}: {value}")
        else:
            unchanged_keys += 1

    print(f"   æ•°æ®å˜åŒ–ç»Ÿè®¡: {changed_keys} ä¸ªé”®æœ‰å˜åŒ–, {unchanged_keys} ä¸ªé”®æœªå˜åŒ–")
    print(f"   æ•°æ®ä¸€è‡´æ€§é—®é¢˜: {data_consistency_issues} ä¸ª")

    # 2. æµ‹è¯•æ•°æ®ä¸¢å¤±æƒ…å†µ
    print("2. æµ‹è¯•æ•°æ®å®Œæ•´æ€§...")

    # è®°å½•æ‰€æœ‰é”®
    all_keys_before = set(redis_client.keys("*"))

    # ç­‰å¾…ä¸€æ®µæ—¶é—´
    time.sleep(5)

    # æ£€æŸ¥é”®æ˜¯å¦ä¸¢å¤±
    all_keys_after = set(redis_client.keys("*"))

    lost_keys = all_keys_before - all_keys_after
    new_keys = all_keys_after - all_keys_before

    if lost_keys:
        print(f"   âš ï¸  ä¸¢å¤±äº† {len(lost_keys)} ä¸ªé”®")
        for key in list(lost_keys)[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
            print(f"      - {key}")
    else:
        print("   âœ… æ²¡æœ‰é”®ä¸¢å¤±")

    if new_keys:
        print(f"   ğŸ“ˆ æ–°å¢äº† {len(new_keys)} ä¸ªé”®")
        for key in list(new_keys)[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
            print(f"      + {key}")

    # 3. æµ‹è¯•Redisè¿æ¥ç¨³å®šæ€§
    print("3. æµ‹è¯•Redisè¿æ¥ç¨³å®šæ€§...")

    connection_tests = 20
    successful_connections = 0

    for i in range(connection_tests):
        try:
            test_client = redis.from_url(redis_url, decode_responses=True)
            result = test_client.ping()
            if result:
                successful_connections += 1
            test_client.close()
        except Exception as e:
            print(f"   âŒ è¿æ¥æµ‹è¯• {i + 1} å¤±è´¥: {e}")

        time.sleep(0.1)  # çŸ­æš‚é—´éš”

    connection_rate = successful_connections / connection_tests * 100
    print(
        f"   è¿æ¥æˆåŠŸç‡: {connection_rate:.1f}% ({successful_connections}/{connection_tests})"
    )

    # 4. æµ‹è¯•æ•°æ®è¯»å†™æ€§èƒ½æŒç»­æ€§
    print("4. æµ‹è¯•æ•°æ®è¯»å†™æ€§èƒ½...")

    # å†™å…¥æµ‹è¯•æ•°æ®
    test_key = "test:persistence:data"
    test_data = {f"point_{i}": f"{i * 1.234567:.6f}" for i in range(100)}

    write_times = []
    read_times = []

    # æ‰§è¡Œå¤šæ¬¡è¯»å†™æµ‹è¯•
    for i in range(10):
        # å†™å…¥æµ‹è¯•
        start_time = time.time()
        redis_client.hset(test_key, mapping=test_data)
        write_time = (time.time() - start_time) * 1000
        write_times.append(write_time)

        # è¯»å–æµ‹è¯•
        start_time = time.time()
        read_data = redis_client.hgetall(test_key)
        read_time = (time.time() - start_time) * 1000
        read_times.append(read_time)

        # éªŒè¯æ•°æ®å®Œæ•´æ€§
        if len(read_data) != len(test_data):
            print(
                f"   âŒ æ•°æ®å®Œæ•´æ€§é—®é¢˜: æœŸæœ› {len(test_data)} ä¸ªå­—æ®µ, å®é™… {len(read_data)} ä¸ª"
            )

        time.sleep(0.5)

    avg_write_time = sum(write_times) / len(write_times)
    avg_read_time = sum(read_times) / len(read_times)

    print(f"   å¹³å‡å†™å…¥æ—¶é—´: {avg_write_time:.2f}ms")
    print(f"   å¹³å‡è¯»å–æ—¶é—´: {avg_read_time:.2f}ms")

    # æ¸…ç†æµ‹è¯•æ•°æ®
    redis_client.delete(test_key)

    # 5. æµ‹è¯•ModSrv APIæŒç»­æ€§
    print("5. æµ‹è¯•ModSrv APIæŒç»­æ€§...")

    api_tests = 10
    successful_api_calls = 0
    api_response_times = []

    for i in range(api_tests):
        try:
            start_time = time.time()
            response = requests.get(f"{modsrv_url}/health", timeout=5)
            response_time = (time.time() - start_time) * 1000
            api_response_times.append(response_time)

            if response.status_code == 200:
                successful_api_calls += 1
            else:
                print(f"   âš ï¸  APIæµ‹è¯• {i + 1} è¿”å›çŠ¶æ€ç : {response.status_code}")

        except Exception as e:
            print(f"   âŒ APIæµ‹è¯• {i + 1} å¤±è´¥: {e}")

        time.sleep(1)

    api_success_rate = successful_api_calls / api_tests * 100
    avg_api_response_time = (
        sum(api_response_times) / len(api_response_times) if api_response_times else 0
    )

    print(f"   APIæˆåŠŸç‡: {api_success_rate:.1f}% ({successful_api_calls}/{api_tests})")
    print(f"   å¹³å‡APIå“åº”æ—¶é—´: {avg_api_response_time:.2f}ms")

    # 6. æµ‹è¯•é•¿æœŸè¿è¡Œç¨³å®šæ€§
    print("6. æµ‹è¯•é•¿æœŸè¿è¡Œç¨³å®šæ€§...")

    # æ¨¡æ‹Ÿé•¿æœŸè¿è¡Œåœºæ™¯
    stability_test_duration = 30  # ç§’
    check_interval = 5  # ç§’
    stability_checks = []

    start_time = time.time()
    next_check = start_time + check_interval

    while time.time() - start_time < stability_test_duration:
        current_time = time.time()

        if current_time >= next_check:
            try:
                # æ£€æŸ¥RedisçŠ¶æ€
                redis_info = redis_client.info()
                memory_usage = redis_info.get("used_memory", 0)
                client_count = redis_info.get("connected_clients", 0)

                # æ£€æŸ¥APIçŠ¶æ€
                api_response = requests.get(f"{modsrv_url}/health", timeout=3)
                api_ok = api_response.status_code == 200

                # æ£€æŸ¥æ•°æ®é”®æ•°é‡
                key_count = len(redis_client.keys("*"))

                stability_checks.append(
                    {
                        "timestamp": current_time,
                        "memory_usage": memory_usage,
                        "client_count": client_count,
                        "api_ok": api_ok,
                        "key_count": key_count,
                    }
                )

                elapsed = current_time - start_time
                remaining = stability_test_duration - elapsed
                print(
                    f"   ç¨³å®šæ€§æ£€æŸ¥: {elapsed:.1f}s / {stability_test_duration}s (å‰©ä½™: {remaining:.1f}s)"
                )

            except Exception as e:
                print(f"   âš ï¸  ç¨³å®šæ€§æ£€æŸ¥å¼‚å¸¸: {e}")

            next_check = current_time + check_interval

        time.sleep(1)

    # åˆ†æç¨³å®šæ€§ç»“æœ
    if stability_checks:
        memory_values = [check["memory_usage"] for check in stability_checks]
        client_values = [check["client_count"] for check in stability_checks]
        key_values = [check["key_count"] for check in stability_checks]
        api_success_count = sum(1 for check in stability_checks if check["api_ok"])

        memory_growth = max(memory_values) - min(memory_values)
        client_variance = max(client_values) - min(client_values)
        key_variance = max(key_values) - min(key_values)
        api_stability = api_success_count / len(stability_checks) * 100

        print(f"   å†…å­˜å¢é•¿: {memory_growth} bytes")
        print(f"   å®¢æˆ·ç«¯è¿æ¥å˜åŒ–: {client_variance}")
        print(f"   é”®æ•°é‡å˜åŒ–: {key_variance}")
        print(f"   APIç¨³å®šæ€§: {api_stability:.1f}%")

    # 7. ç»¼åˆè¯„ä¼°
    print("7. ç»¼åˆè¯„ä¼°...")

    issues = []

    if data_consistency_issues > 0:
        issues.append(f"æ•°æ®ä¸€è‡´æ€§é—®é¢˜: {data_consistency_issues} ä¸ª")

    if len(lost_keys) > 0:
        issues.append(f"æ•°æ®ä¸¢å¤±: {len(lost_keys)} ä¸ªé”®")

    if connection_rate < 95:
        issues.append(f"è¿æ¥ç¨³å®šæ€§ä¸è¶³: {connection_rate:.1f}%")

    if avg_write_time > 100:  # 100ms
        issues.append(f"å†™å…¥æ€§èƒ½è¿‡æ…¢: {avg_write_time:.2f}ms")

    if avg_read_time > 50:  # 50ms
        issues.append(f"è¯»å–æ€§èƒ½è¿‡æ…¢: {avg_read_time:.2f}ms")

    if api_success_rate < 95:
        issues.append(f"APIç¨³å®šæ€§ä¸è¶³: {api_success_rate:.1f}%")

    if issues:
        print("   âŒ å‘ç°é—®é¢˜:")
        for issue in issues:
            print(f"      - {issue}")
        print("   æ•°æ®æŒç»­æ€§æµ‹è¯•æœªå®Œå…¨é€šè¿‡")
        return False
    else:
        print("   âœ… æ‰€æœ‰æŒç»­æ€§æµ‹è¯•é€šè¿‡")
        print("   ç³»ç»Ÿæ•°æ®æŒç»­æ€§è¡¨ç°è‰¯å¥½")
        return True


if __name__ == "__main__":
    try:
        if test_data_persistence():
            print("æ•°æ®æŒç»­æ€§æµ‹è¯•: PASS")
        else:
            print("æ•°æ®æŒç»­æ€§æµ‹è¯•: FAIL - å­˜åœ¨æŒç»­æ€§é—®é¢˜")
            exit(1)
    except Exception as e:
        print(f"æ•°æ®æŒç»­æ€§æµ‹è¯•: FAIL - {e}")
        exit(1)

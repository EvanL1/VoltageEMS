# HisSrv å¤§æ•°æ®å­˜å‚¨æ¶æ„è®¾è®¡

## ğŸ¯ è®¾è®¡ç›®æ ‡

- **æ€§èƒ½**: å¿«é€ŸæŸ¥è¯¢å“åº” (< 2ç§’)
- **æˆæœ¬**: åˆç†çš„å­˜å‚¨æˆæœ¬
- **æ‰©å±•æ€§**: æ”¯æŒæ•°æ®é‡æŒç»­å¢é•¿
- **å¯é æ€§**: æ•°æ®ä¸ä¸¢å¤±ï¼Œé«˜å¯ç”¨

## ğŸ—ï¸ åˆ†å±‚å­˜å‚¨æ¶æ„

### 1. çƒ­æ•°æ®å±‚ (Redis) - æœ€è¿‘7å¤©
```
ç”¨é€”: å®æ—¶æŸ¥è¯¢ã€dashboardå±•ç¤º
å®¹é‡: ~100GB
ä¿ç•™: 7å¤©
æŸ¥è¯¢: æ¯«ç§’çº§å“åº”
```

### 2. æ¸©æ•°æ®å±‚ (InfluxDB) - æœ€è¿‘3ä¸ªæœˆ  
```
ç”¨é€”: å¸¸ç”¨å†å²æŸ¥è¯¢ã€æŠ¥è¡¨
å®¹é‡: ~1TB
ä¿ç•™: 3ä¸ªæœˆ
æŸ¥è¯¢: ç§’çº§å“åº”
```

### 3. å†·æ•°æ®å±‚ (PostgreSQL + æ–‡ä»¶å­˜å‚¨) - é•¿æœŸå½’æ¡£
```
ç”¨é€”: é•¿æœŸå­˜å‚¨ã€åˆè§„æ€§è¦æ±‚
å®¹é‡: æ— é™åˆ¶
ä¿ç•™: æ°¸ä¹…/æŒ‰æ”¿ç­–
æŸ¥è¯¢: åˆ†é’Ÿçº§å“åº”ï¼ˆé¢„èšåˆï¼‰
```

## ğŸ“ˆ æ•°æ®ç”Ÿå‘½å‘¨æœŸç®¡ç†

```mermaid
graph LR
    A[å®æ—¶æ•°æ®] --> B[Redis 7å¤©]
    B --> C[InfluxDB 3ä¸ªæœˆ] 
    C --> D[PostgreSQL æ°¸ä¹…]
    
    B -.-> E[Redisè¿‡æœŸè‡ªåŠ¨æ¸…ç†]
    C -.-> F[å®šæ—¶ä»»åŠ¡è¿ç§»]
    D -.-> G[å‹ç¼©/å½’æ¡£]
```

### è‡ªåŠ¨æ•°æ®è¿ç§»ç­–ç•¥

#### 1. çƒ­->æ¸© è¿ç§» (æ¯æ—¥å‡Œæ™¨)
```yaml
schedule: "0 2 * * *"  # æ¯å¤©å‡Œæ™¨2ç‚¹
action: |
  1. æŸ¥è¯¢Redisä¸­7å¤©å‰çš„æ•°æ®
  2. æ‰¹é‡å†™å…¥InfluxDB
  3. ä»Redisä¸­åˆ é™¤
  4. éªŒè¯æ•°æ®å®Œæ•´æ€§
```

#### 2. æ¸©->å†· è¿ç§» (æ¯å‘¨æ‰§è¡Œ)
```yaml
schedule: "0 3 * * 0"  # æ¯å‘¨æ—¥å‡Œæ™¨3ç‚¹
action: |
  1. èšåˆInfluxDBä¸­3ä¸ªæœˆå‰çš„æ•°æ®
  2. å†™å…¥PostgreSQL (å·²èšåˆ)
  3. åŸå§‹æ•°æ®å½’æ¡£åˆ°æ–‡ä»¶å­˜å‚¨
  4. ä»InfluxDBä¸­åˆ é™¤åŸå§‹æ•°æ®
```

## ğŸ” æ™ºèƒ½æŸ¥è¯¢è·¯ç”±

### æŸ¥è¯¢è·¯ç”±ç­–ç•¥
```rust
pub async fn route_query(filter: &HistoryQueryFilter) -> QueryPlan {
    let now = Utc::now();
    let duration = filter.end_time - filter.start_time;
    
    match (filter.start_time, duration) {
        // æœ€è¿‘7å¤©çš„æ•°æ® -> Redis
        _ if filter.start_time > now - Duration::days(7) => {
            QueryPlan::Redis {
                fast_path: true,
                expected_response_time: "< 100ms"
            }
        },
        
        // æœ€è¿‘3ä¸ªæœˆçš„æ•°æ® -> InfluxDB
        _ if filter.start_time > now - Duration::days(90) => {
            QueryPlan::InfluxDB {
                use_downsampling: duration > Duration::days(7),
                expected_response_time: "< 2s"
            }
        },
        
        // æ›´è€çš„æ•°æ® -> PostgreSQL (é¢„èšåˆ)
        _ => {
            QueryPlan::PostgreSQL {
                force_aggregation: true,
                max_raw_data_days: 1,
                expected_response_time: "< 30s"
            }
        }
    }
}
```

## ğŸ’¾ å­˜å‚¨å±‚è¯¦ç»†è®¾è®¡

### 1. Redis çƒ­æ•°æ®å±‚

#### æ•°æ®ç»“æ„è®¾è®¡
```redis
# åŸå§‹æ•°æ®ç‚¹ (ä¿ç•™7å¤©)
hissrv:raw:{source_id}:{point_name}:{date} -> ZSET(timestamp, json_data)

# åˆ†é’Ÿçº§èšåˆ (ä¿ç•™7å¤©)  
hissrv:agg:1m:{source_id}:{point_name}:{date} -> ZSET(timestamp, avg_value)

# å°æ—¶çº§èšåˆ (ä¿ç•™30å¤©)
hissrv:agg:1h:{source_id}:{point_name}:{date} -> ZSET(timestamp, avg_value)
```

#### å†…å­˜ä¼˜åŒ–ç­–ç•¥
```yaml
memory_policy: "allkeys-lru"
max_memory: "8GB"
compression: true
expire_strategy: "ttl_based"  # è‡ªåŠ¨è¿‡æœŸ
```

### 2. InfluxDB æ¸©æ•°æ®å±‚

#### Retention Policy è®¾è®¡
```sql
-- åŸå§‹æ•°æ®ä¿ç•™3ä¸ªæœˆ
CREATE RETENTION POLICY "raw_3months" ON "hissrv" 
DURATION 90d REPLICATION 1 DEFAULT

-- 1åˆ†é’Ÿèšåˆä¿ç•™1å¹´
CREATE RETENTION POLICY "agg_1m_1year" ON "hissrv" 
DURATION 365d REPLICATION 1

-- 1å°æ—¶èšåˆä¿ç•™5å¹´
CREATE RETENTION POLICY "agg_1h_5years" ON "hissrv" 
DURATION 1825d REPLICATION 1
```

#### è¿ç»­æŸ¥è¯¢è‡ªåŠ¨èšåˆ
```sql
-- è‡ªåŠ¨ç”Ÿæˆ1åˆ†é’Ÿèšåˆ
CREATE CONTINUOUS QUERY "cq_1m_avg" ON "hissrv"
BEGIN
  SELECT mean(value) as value
  INTO "hissrv"."agg_1m_1year"."data_1m"
  FROM "hissrv"."raw_3months"."data"
  GROUP BY time(1m), source_id, point_name
END

-- è‡ªåŠ¨ç”Ÿæˆ1å°æ—¶èšåˆ  
CREATE CONTINUOUS QUERY "cq_1h_avg" ON "hissrv"
BEGIN
  SELECT mean(value) as value
  INTO "hissrv"."agg_1h_5years"."data_1h" 
  FROM "hissrv"."agg_1m_1year"."data_1m"
  GROUP BY time(1h), source_id, point_name
END
```

### 3. PostgreSQL å†·æ•°æ®å±‚

#### è¡¨ç»“æ„è®¾è®¡
```sql
-- é¢„èšåˆçš„å†å²æ•°æ®è¡¨
CREATE TABLE historical_data_aggregated (
    id BIGSERIAL PRIMARY KEY,
    source_id VARCHAR(100) NOT NULL,
    point_name VARCHAR(100) NOT NULL,
    time_bucket TIMESTAMP NOT NULL,
    aggregation_level VARCHAR(10) NOT NULL, -- '1h', '1d', '1w'
    avg_value DOUBLE PRECISION,
    min_value DOUBLE PRECISION,
    max_value DOUBLE PRECISION,
    count_value BIGINT,
    created_at TIMESTAMP DEFAULT NOW()
);

-- åˆ†åŒºè¡¨ (æŒ‰æœˆåˆ†åŒº)
CREATE TABLE historical_data_aggregated_y2024m01 
PARTITION OF historical_data_aggregated
FOR VALUES FROM ('2024-01-01') TO ('2024-02-01');

-- ç´¢å¼•ä¼˜åŒ–
CREATE INDEX idx_hist_agg_source_time 
ON historical_data_aggregated (source_id, time_bucket);

CREATE INDEX idx_hist_agg_point_time 
ON historical_data_aggregated (point_name, time_bucket);
```

#### åŸå§‹æ•°æ®å½’æ¡£
```sql
-- å½’æ¡£æ–‡ä»¶å­˜å‚¨è¡¨
CREATE TABLE archived_data_files (
    id BIGSERIAL PRIMARY KEY,
    file_path TEXT NOT NULL,
    start_time TIMESTAMP NOT NULL,
    end_time TIMESTAMP NOT NULL,
    source_ids TEXT[], -- åŒ…å«çš„æ•°æ®æº
    compression_format VARCHAR(20), -- 'gzip', 'lz4'
    file_size_bytes BIGINT,
    checksum VARCHAR(64),
    created_at TIMESTAMP DEFAULT NOW()
);
```

## âš¡ æŸ¥è¯¢ä¼˜åŒ–ç­–ç•¥

### 1. æ™ºèƒ½é™é‡‡æ ·
```rust
fn determine_sampling_strategy(
    time_range: Duration,
    expected_points: u32
) -> SamplingStrategy {
    let target_points = 1000; // ç›®æ ‡è¿”å›ç‚¹æ•°
    
    if expected_points <= target_points {
        SamplingStrategy::Raw
    } else {
        let interval = time_range.num_seconds() / target_points as i64;
        match interval {
            0..=60 => SamplingStrategy::Aggregate("1m"),
            61..=3600 => SamplingStrategy::Aggregate("1h"), 
            _ => SamplingStrategy::Aggregate("1d")
        }
    }
}
```

### 2. ç¼“å­˜ç­–ç•¥
```yaml
query_cache:
  # æŸ¥è¯¢ç»“æœç¼“å­˜
  result_cache:
    ttl: "15m"
    max_size: "1GB"
    key_pattern: "query:{hash}"
  
  # èšåˆç»“æœç¼“å­˜
  aggregation_cache:
    ttl: "1h" 
    max_size: "2GB"
    key_pattern: "agg:{source}:{interval}:{time}"
    
  # å…ƒæ•°æ®ç¼“å­˜
  metadata_cache:
    ttl: "1d"
    max_size: "100MB"
    key_pattern: "meta:{source}"
```

### 3. å¹¶è¡ŒæŸ¥è¯¢
```rust
pub async fn execute_multi_layer_query(
    filter: &HistoryQueryFilter
) -> Result<HistoryQueryResult> {
    let mut tasks = Vec::new();
    
    // å¹¶è¡ŒæŸ¥è¯¢å¤šä¸ªå­˜å‚¨å±‚
    if needs_redis_data(&filter) {
        tasks.push(query_redis_layer(filter));
    }
    
    if needs_influxdb_data(&filter) {
        tasks.push(query_influxdb_layer(filter));
    }
    
    if needs_postgresql_data(&filter) {
        tasks.push(query_postgresql_layer(filter));
    }
    
    // ç­‰å¾…æ‰€æœ‰æŸ¥è¯¢å®Œæˆå¹¶åˆå¹¶ç»“æœ
    let results = futures::try_join_all(tasks).await?;
    merge_query_results(results)
}
```

## ğŸ“Š æ•°æ®å‹ç¼©å’Œå­˜å‚¨ä¼˜åŒ–

### 1. InfluxDB å‹ç¼©
```toml
[data]
  # å¯ç”¨å‹ç¼©
  index-version = "inmem"
  wal-dir = "/var/lib/influxdb/wal"
  
  # å‹ç¼©è®¾ç½®
  compact-full-write-cold-duration = "4h"
  compact-throughput = "48m"
  compact-throughput-burst = "48m"
  
  # TSMæ–‡ä»¶å‹ç¼©
  tsm-use-madv-willneed = true
```

### 2. PostgreSQL å‹ç¼©
```sql
-- è¡¨çº§å‹ç¼©
ALTER TABLE historical_data_aggregated 
SET (toast_compression = 'lz4');

-- åˆ†åŒºè¡¨è‡ªåŠ¨å‹ç¼©
CREATE OR REPLACE FUNCTION compress_old_partitions()
RETURNS void AS $$
DECLARE
    partition_name text;
BEGIN
    FOR partition_name IN 
        SELECT tablename FROM pg_tables 
        WHERE tablename LIKE 'historical_data_aggregated_y%'
        AND tablename < 'historical_data_aggregated_y' || 
                        to_char(now() - interval '3 months', 'YYYY"m"MM')
    LOOP
        EXECUTE 'SELECT pg_compress_table(''' || partition_name || ''')';
    END LOOP;
END;
$$ LANGUAGE plpgsql;
```

## ğŸ”„ æ•°æ®è¿ç§»å®ç°

### è‡ªåŠ¨è¿ç§»æœåŠ¡
```rust
pub struct DataMigrationService {
    redis: RedisConnection,
    influxdb: InfluxDBConnection,
    postgres: PostgresConnection,
}

impl DataMigrationService {
    pub async fn run_daily_migration(&self) -> Result<()> {
        // 1. Redis -> InfluxDB è¿ç§»
        self.migrate_redis_to_influxdb().await?;
        
        // 2. æ¸…ç†è¿‡æœŸRedisæ•°æ®
        self.cleanup_expired_redis_data().await?;
        
        Ok(())
    }
    
    pub async fn run_weekly_migration(&self) -> Result<()> {
        // 1. InfluxDB -> PostgreSQL èšåˆè¿ç§»
        self.migrate_influxdb_to_postgres().await?;
        
        // 2. åŸå§‹æ•°æ®å½’æ¡£
        self.archive_raw_data().await?;
        
        // 3. æ¸…ç†InfluxDBæ—§æ•°æ®
        self.cleanup_old_influxdb_data().await?;
        
        Ok(())
    }
}
```

## ğŸ“ˆ ç›‘æ§å’Œè¿ç»´

### å…³é”®æŒ‡æ ‡ç›‘æ§
```yaml
storage_metrics:
  redis:
    - memory_usage
    - hit_rate
    - expired_keys_per_sec
    
  influxdb:
    - disk_usage
    - query_response_time
    - compaction_status
    
  postgresql:
    - table_size
    - query_performance
    - partition_count

query_metrics:
  - query_response_time_p99
  - cache_hit_rate
  - data_points_returned
  - query_complexity_score
```

### è‡ªåŠ¨æŠ¥è­¦è§„åˆ™
```yaml
alerts:
  - name: "redis_memory_high"
    condition: "redis_memory_usage > 80%"
    action: "trigger_data_migration"
    
  - name: "query_slow"
    condition: "query_response_time_p99 > 10s"
    action: "enable_aggressive_caching"
    
  - name: "storage_full"
    condition: "disk_usage > 85%"
    action: "accelerate_data_archival"
```

## ğŸ’¡ æœ€ä½³å®è·µå»ºè®®

### 1. æŸ¥è¯¢è®¾è®¡åŸåˆ™
- **æ—¶é—´èŒƒå›´é™åˆ¶**: å•æ¬¡æŸ¥è¯¢ä¸è¶…è¿‡1å¹´
- **é™é‡‡æ ·ç­–ç•¥**: å¤§æ—¶é—´èŒƒå›´è‡ªåŠ¨ä½¿ç”¨èšåˆæ•°æ®
- **åˆ†é¡µæŸ¥è¯¢**: å¤§ç»“æœé›†åˆ†æ‰¹è¿”å›
- **ç¼“å­˜ä¼˜å…ˆ**: ç›¸åŒæŸ¥è¯¢å¤ç”¨ç¼“å­˜ç»“æœ

### 2. æ•°æ®å»ºæ¨¡åŸåˆ™
- **æ ‡ç­¾è®¾è®¡**: åˆç†ä½¿ç”¨tagsï¼Œé¿å…é«˜åŸºæ•°
- **åˆ†åŒºç­–ç•¥**: æŒ‰æ—¶é—´åˆ†åŒºï¼Œä¾¿äºæ•°æ®ç®¡ç†
- **ç´¢å¼•ä¼˜åŒ–**: åŸºäºæŸ¥è¯¢æ¨¡å¼åˆ›å»ºç´¢å¼•
- **æ•°æ®ç±»å‹**: é€‰æ‹©åˆé€‚çš„æ•°æ®ç±»å‹èŠ‚çœç©ºé—´

### 3. å®¹é‡è§„åˆ’
- **å¢é•¿é¢„ä¼°**: åŸºäºå½“å‰å¢é•¿ç‡é¢„ä¼°å®¹é‡éœ€æ±‚
- **å­˜å‚¨åˆ†çº§**: æ ¹æ®è®¿é—®é¢‘ç‡é…ç½®å­˜å‚¨å±‚çº§
- **å¤‡ä»½ç­–ç•¥**: å…³é”®æ•°æ®å¤šé‡å¤‡ä»½
- **æ‰©å®¹è®¡åˆ’**: æå‰è§„åˆ’æ¨ªå‘æ‰©å®¹æ–¹æ¡ˆ

è¿™ç§æ¶æ„è®¾è®¡å¯ä»¥ï¼š
- âœ… å¤„ç†TBçº§åˆ«çš„å†å²æ•°æ®
- âœ… æä¾›æ¯«ç§’åˆ°ç§’çº§çš„æŸ¥è¯¢å“åº”
- âœ… è‡ªåŠ¨ç®¡ç†æ•°æ®ç”Ÿå‘½å‘¨æœŸ
- âœ… æ§åˆ¶å­˜å‚¨æˆæœ¬
- âœ… æ”¯æŒæ°´å¹³æ‰©å±•
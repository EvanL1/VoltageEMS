# Test Data Initializer
FROM python:3.11-slim

RUN apt-get update && apt-get install -y \
    redis-tools \
    curl \
    && rm -rf /var/lib/apt/lists/*

WORKDIR /app

# Install Python dependencies
RUN pip install --no-cache-dir \
    redis \
    influxdb-client \
    pyyaml \
    pandas \
    numpy

# Create test data initialization script
RUN cat > /app/init_test_data.py << 'EOF'
#!/usr/bin/env python3
"""
Test Data Initializer for VoltageEMS
Initializes Redis and InfluxDB with test data
"""

import redis
import json
import time
import random
import yaml
import os
from datetime import datetime, timedelta
from influxdb_client import InfluxDBClient, Point
from influxdb_client.client.write_api import SYNCHRONOUS
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class TestDataInitializer:
    def __init__(self):
        self.redis_client = redis.Redis(host='redis-test', port=6379, decode_responses=True)
        
        influxdb_url = os.getenv('INFLUXDB_URL', 'http://influxdb-test:8086')
        influxdb_token = os.getenv('INFLUXDB_TOKEN', 'test-token-123')
        influxdb_org = os.getenv('INFLUXDB_ORG', 'voltageems-test')
        
        self.influxdb_client = InfluxDBClient(
            url=influxdb_url,
            token=influxdb_token,
            org=influxdb_org
        )
        self.bucket = os.getenv('INFLUXDB_BUCKET', 'test_data')

    def wait_for_services(self):
        """Wait for Redis and InfluxDB to be ready"""
        logger.info("Waiting for services to be ready...")
        
        # Wait for Redis
        max_retries = 30
        for i in range(max_retries):
            try:
                self.redis_client.ping()
                logger.info("Redis is ready")
                break
            except:
                if i == max_retries - 1:
                    raise Exception("Redis is not available")
                time.sleep(2)
        
        # Wait for InfluxDB
        for i in range(max_retries):
            try:
                self.influxdb_client.ping()
                logger.info("InfluxDB is ready")
                break
            except:
                if i == max_retries - 1:
                    raise Exception("InfluxDB is not available")
                time.sleep(2)

    def init_redis_test_data(self):
        """Initialize Redis with test data"""
        logger.info("Initializing Redis test data...")
        
        # Initialize test channels
        channels = [
            {'id': 1001, 'name': 'test_channel_1', 'type': 'modbus'},
            {'id': 1002, 'name': 'test_channel_2', 'type': 'virtual'},
            {'id': 1003, 'name': 'test_channel_3', 'type': 'modbus'}
        ]
        
        for channel in channels:
            channel_key = f"comsrv:channel:{channel['id']}"
            self.redis_client.hset(channel_key, mapping=channel)
        
        # Initialize test points for each channel
        point_types = ['T', 'S', 'C', 'A']  # Telemetry, Signal, Control, Adjustment
        
        for channel in channels:
            channel_id = channel['id']
            
            for point_type in point_types:
                hash_key = f"comsrv:{channel_id}:{point_type}"
                
                # Create sample points
                for point_id in range(1, 11):  # 10 points per type
                    if point_type == 'T':  # Telemetry - float values
                        value = round(random.uniform(20.0, 100.0), 6)
                    elif point_type == 'S':  # Signal - boolean values  
                        value = random.choice([0.0, 1.0])
                    elif point_type == 'C':  # Control - integer values
                        value = float(random.randint(0, 255))
                    else:  # Adjustment - float values
                        value = round(random.uniform(-10.0, 10.0), 6)
                    
                    self.redis_client.hset(hash_key, str(point_id), value)
        
        # Initialize test models
        models = [
            {
                'id': 'model_001',
                'name': 'Test Model 1',
                'description': 'Test model for unit testing',
                'channel_id': 1001,
                'points': [1, 2, 3, 4, 5]
            },
            {
                'id': 'model_002', 
                'name': 'Test Model 2',
                'description': 'Test model for integration testing',
                'channel_id': 1002,
                'points': [6, 7, 8, 9, 10]
            }
        ]
        
        for model in models:
            model_key = f"modsrv:model:{model['id']}"
            self.redis_client.hset(model_key, mapping={
                'data': json.dumps(model)
            })
        
        # Initialize test alarms
        alarms = [
            {
                'id': 'alarm_001',
                'title': 'High Temperature Alarm',
                'description': 'Temperature exceeded threshold',
                'level': 'Critical',
                'status': 'Active',
                'created_at': datetime.now().isoformat()
            },
            {
                'id': 'alarm_002',
                'title': 'Low Pressure Alarm', 
                'description': 'Pressure below minimum',
                'level': 'Warning',
                'status': 'Acknowledged',
                'created_at': (datetime.now() - timedelta(hours=1)).isoformat()
            }
        ]
        
        for alarm in alarms:
            alarm_key = f"alarmsrv:alarm:{alarm['id']}"
            self.redis_client.hset(alarm_key, mapping={
                'data': json.dumps(alarm)
            })
        
        # Initialize test rules
        rules = [
            {
                'id': 'rule_001',
                'name': 'Temperature Check Rule',
                'description': 'Check if temperature is within normal range',
                'conditions': [
                    {'point_id': 1, 'operator': 'greater_than', 'value': 80.0}
                ],
                'actions': [
                    {'type': 'alarm', 'alarm_id': 'alarm_001'}
                ],
                'enabled': True
            }
        ]
        
        for rule in rules:
            rule_key = f"rulesrv:rule:{rule['id']}"
            self.redis_client.hset(rule_key, mapping={
                'data': json.dumps(rule)
            })
        
        logger.info("Redis test data initialized successfully")

    def init_influxdb_test_data(self):
        """Initialize InfluxDB with test time-series data"""
        logger.info("Initializing InfluxDB test data...")
        
        write_api = self.influxdb_client.write_api(write_options=SYNCHRONOUS)
        
        # Generate historical data for the last 24 hours
        end_time = datetime.now()
        start_time = end_time - timedelta(hours=24)
        
        points = []
        current_time = start_time
        
        while current_time <= end_time:
            # Generate data for different measurement types
            measurements = [
                {
                    'measurement': 'telemetry',
                    'tags': {'channel_id': '1001', 'point_id': '1'},
                    'fields': {'value': random.uniform(20.0, 100.0)},
                    'time': current_time
                },
                {
                    'measurement': 'telemetry',
                    'tags': {'channel_id': '1001', 'point_id': '2'},
                    'fields': {'value': random.uniform(30.0, 90.0)},
                    'time': current_time
                },
                {
                    'measurement': 'signal',
                    'tags': {'channel_id': '1002', 'point_id': '1'},
                    'fields': {'value': random.choice([0, 1])},
                    'time': current_time
                }
            ]
            
            for measurement in measurements:
                point = Point(measurement['measurement'])
                for tag_key, tag_value in measurement['tags'].items():
                    point = point.tag(tag_key, tag_value)
                for field_key, field_value in measurement['fields'].items():
                    point = point.field(field_key, field_value)
                point = point.time(measurement['time'])
                points.append(point)
            
            current_time += timedelta(minutes=5)  # 5-minute intervals
        
        # Write points in batches
        batch_size = 1000
        for i in range(0, len(points), batch_size):
            batch = points[i:i + batch_size]
            try:
                write_api.write(bucket=self.bucket, record=batch)
            except Exception as e:
                logger.error(f"Error writing batch {i//batch_size + 1}: {e}")
        
        logger.info(f"InfluxDB test data initialized successfully ({len(points)} points)")

    def verify_data_initialization(self):
        """Verify that test data was initialized correctly"""
        logger.info("Verifying test data initialization...")
        
        # Verify Redis data
        redis_keys = self.redis_client.keys('*')
        logger.info(f"Redis keys created: {len(redis_keys)}")
        
        # Verify specific data
        channel_keys = [k for k in redis_keys if k.startswith('comsrv:channel:')]
        model_keys = [k for k in redis_keys if k.startswith('modsrv:model:')]
        alarm_keys = [k for k in redis_keys if k.startswith('alarmsrv:alarm:')]
        rule_keys = [k for k in redis_keys if k.startswith('rulesrv:rule:')]
        
        logger.info(f"Channels: {len(channel_keys)}")
        logger.info(f"Models: {len(model_keys)}")
        logger.info(f"Alarms: {len(alarm_keys)}")
        logger.info(f"Rules: {len(rule_keys)}")
        
        # Verify InfluxDB data
        query_api = self.influxdb_client.query_api()
        query = f'''
            from(bucket: "{self.bucket}")
            |> range(start: -24h)
            |> count()
        '''
        
        try:
            result = query_api.query(query)
            total_points = 0
            for table in result:
                for record in table.records:
                    total_points += record.get_value()
            
            logger.info(f"InfluxDB points: {total_points}")
        except Exception as e:
            logger.warning(f"Could not verify InfluxDB data: {e}")
        
        logger.info("Data verification completed")

    def run(self):
        """Run the initialization process"""
        logger.info("Starting test data initialization...")
        
        try:
            self.wait_for_services()
            self.init_redis_test_data()
            self.init_influxdb_test_data()
            self.verify_data_initialization()
            
            logger.info("Test data initialization completed successfully")
            
        except Exception as e:
            logger.error(f"Test data initialization failed: {e}")
            raise
        
        finally:
            self.influxdb_client.close()

if __name__ == "__main__":
    initializer = TestDataInitializer()
    initializer.run()
EOF

RUN chmod +x /app/init_test_data.py

CMD ["python", "/app/init_test_data.py"]